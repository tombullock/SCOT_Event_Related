{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dea3254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:root:code for hash md5 was not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 147, in <module>\n",
      "    globals()[__func_name] = __get_hash(__func_name)\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 97, in __get_builtin_constructor\n",
      "    raise ValueError('unsupported hash type ' + name)\n",
      "ValueError: unsupported hash type md5\n",
      "ERROR:root:code for hash sha1 was not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 147, in <module>\n",
      "    globals()[__func_name] = __get_hash(__func_name)\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 97, in __get_builtin_constructor\n",
      "    raise ValueError('unsupported hash type ' + name)\n",
      "ValueError: unsupported hash type sha1\n",
      "ERROR:root:code for hash sha224 was not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 147, in <module>\n",
      "    globals()[__func_name] = __get_hash(__func_name)\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 97, in __get_builtin_constructor\n",
      "    raise ValueError('unsupported hash type ' + name)\n",
      "ValueError: unsupported hash type sha224\n",
      "ERROR:root:code for hash sha256 was not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 147, in <module>\n",
      "    globals()[__func_name] = __get_hash(__func_name)\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 97, in __get_builtin_constructor\n",
      "    raise ValueError('unsupported hash type ' + name)\n",
      "ValueError: unsupported hash type sha256\n",
      "ERROR:root:code for hash sha384 was not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 147, in <module>\n",
      "    globals()[__func_name] = __get_hash(__func_name)\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 97, in __get_builtin_constructor\n",
      "    raise ValueError('unsupported hash type ' + name)\n",
      "ValueError: unsupported hash type sha384\n",
      "ERROR:root:code for hash sha512 was not found.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 147, in <module>\n",
      "    globals()[__func_name] = __get_hash(__func_name)\n",
      "  File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/hashlib.py\", line 97, in __get_builtin_constructor\n",
      "    raise ValueError('unsupported hash type ' + name)\n",
      "ValueError: unsupported hash type sha512\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/pip\", line 11, in <module>\n",
      "    load_entry_point('pip==19.1.1', 'console_scripts', 'pip')()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 489, in load_entry_point\n",
      "    return get_distribution(dist).load_entry_point(group, name)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 2843, in load_entry_point\n",
      "    return ep.load()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 2434, in load\n",
      "    return self.resolve()\n",
      "  File \"/usr/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 2440, in resolve\n",
      "    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/pip/_internal/__init__.py\", line 19, in <module>\n",
      "    from pip._vendor.urllib3.exceptions import DependencyWarning\n",
      "  File \"/usr/local/lib/python2.7/site-packages/pip/_vendor/urllib3/__init__.py\", line 8, in <module>\n",
      "    from .connectionpool import (\n",
      "  File \"/usr/local/lib/python2.7/site-packages/pip/_vendor/urllib3/connectionpool.py\", line 29, in <module>\n",
      "    from .connection import (\n",
      "  File \"/usr/local/lib/python2.7/site-packages/pip/_vendor/urllib3/connection.py\", line 38, in <module>\n",
      "    from .util.ssl_ import (\n",
      "  File \"/usr/local/lib/python2.7/site-packages/pip/_vendor/urllib3/util/__init__.py\", line 6, in <module>\n",
      "    from .ssl_ import (\n",
      "  File \"/usr/local/lib/python2.7/site-packages/pip/_vendor/urllib3/util/ssl_.py\", line 8, in <module>\n",
      "    from hashlib import md5, sha1, sha256\n",
      "ImportError: cannot import name md5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 18:29:06.898 python[81813:10554618] +[CATransaction synchronize] called within transaction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected contractility channel is Acc dZ (40Hz LP)\n",
      "selected respiration channel is Respiration\n",
      "selected event channel is Experiment Trigger\n",
      "extracting raw signals from AcqKnowledge files...\n",
      "removing slow movements from acceleration data with 7-order polynomial\n",
      "applying lowpass filter to acceleration channel, 22.5 Hz cutoff\n",
      "removing slow movements from respiration data with 7-order polynomial\n",
      "applying lowpass filter to respiration channel, 0.35 Hz cutoff\n",
      "estimating respiration amount and cycle...\n",
      "data loaded!\n"
     ]
    }
   ],
   "source": [
    "## SCOT_Event_Related ##\n",
    "\n",
    "## SCOT Processing Pipeline created by Neil Dundon and adapted by Tom Bullock to visualize and output event-codes/triggers\n",
    "## Date: 09.20.23\n",
    "\n",
    "## CELL 1: LOAD ###\n",
    "# Run this cell to load your datafile through the GUI (currently only works with .acq files, any template).\n",
    "# For each window, select the required option then press click \"X\" to close the window (your selection will be saved) \n",
    "# (1) Select the channel containing acceleration.\n",
    "# (2) Select the channel containing respiration (either resp belt or resp. estimated from z0 timeseries using low-pass filter). \n",
    "# (3) Is there an event channel present?\n",
    "# (4) If there is an event channel present, select the channel.\n",
    "\n",
    "# NOTES: Currently getting \"ImportError: cannot import name md5\" warning messages, but these don't seem prevent the datafile from being loaded successfully.  \n",
    "\n",
    "!pip install bioread\n",
    "from sys_SCOT_Event_Related import loadem\n",
    "cont_dict,file_path=loadem()\n",
    "print('data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe9455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CELL 2: SET THRESHOLD AND ESTIMATE PEAKS ###\n",
    "# Run this cell to open a plot to decide minimum peak height in the acceleration timeseries.\n",
    "# Enter value (will be around ~0.5) in the accompanying GUI.\n",
    "# Programme will then do its first estimate on peak values.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sys_SCOT_Event_Related import compute_peaks,thresh_ind\n",
    "\n",
    "%matplotlib tk\n",
    "plt.close('all')\n",
    "i=thresh_ind(cont_dict['hz'])\n",
    "plt.plot(cont_dict['t'][i],cont_dict['s'][i])\n",
    "peak_times,peak_vals,peak_inds=compute_peaks(cont_dict)\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55a0dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1747.329, 2271.483, 2503.502, 2678.979, 2786.883, 2909.634, 3448.862, 3666.186, 3778.86, 3886.684, 3993.042, 4615.701, 4831.687, 4941.694, 5058.899, 5171.702, 5714.742, 5931.553, 6036.426, 6146.497, 6252.118, 6781.301, 6996.68, 7108.437, 7218.177, 7319.317]\n"
     ]
    }
   ],
   "source": [
    "## CELL 3: INTERACTIVE PLOT - PEAKS IN ACCELERATION TIME SERIES ###\n",
    "# Run this cell to open the interactive plot to visualise and amend peaks in the acceleration time series.\n",
    "# Accleration peaks are more robust to noise and are better estimates of heartbeat times.\n",
    "# Left click - add peak.\n",
    "# Right click - remove peak.\n",
    "# Hold 'm' and left click - use moving average to estimate peak.\n",
    "\n",
    "# Note that the Custom Event Codes section just allows you to input arrays of event codes that mark the beginning and\n",
    "# end of recording blocks.  These event codes are then visualized when you open the interactive plot, allowing you to \n",
    "# clearly see where recording blocks start and end. This can be useful, for example, if you have one long continuous\n",
    "# recording file containing multiple blocks of a task separated by break periods containing data that you won't be \n",
    "# analyzing.  \n",
    "\n",
    "# Note: Edit the custom event codes section to parse \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "import numpy as np\n",
    "from sys_SCOT_Event_Related import *\n",
    "\n",
    "%matplotlib tk\n",
    "plt.close('all')\n",
    "fig,ax = plt.subplots()\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "w = ax.plot(cont_dict['t'],cont_dict['s'])\n",
    "peak_plot, = ax.plot(peak_times,peak_vals ,'vm')\n",
    "\n",
    "\n",
    "## CUSTOM EVENT-CODE VISUALIZATION START HERE ##\n",
    "\n",
    "# isolate event codes and timestamps from dict\n",
    "events = cont_dict['events_s']\n",
    "times = cont_dict['events_t']\n",
    "    \n",
    "code_mat = []\n",
    "time_mat = []\n",
    "\n",
    "# cut out redundant events from oversampling\n",
    "for i in np.arange(np.shape(events)[0]): \n",
    "    if events[i] != 0 and events[i-1] != events[i]:       \n",
    "        code_mat.append(str(int(events[i])))\n",
    "        time_mat.append(round(times[i],3))\n",
    "        \n",
    "# find start of steady state blocks and then calculate end of blocks so we can insert end triggers [note that when we \n",
    "# collected the data we did not send event codes to mark the end of blocks; however, given that we know each block lasts\n",
    "# 90 seconds, we can just create a vector of block end event codes and times here ]\n",
    "start_block_event_codes_ssvep = ['11','12', '13', '21', '22', '23', '31','32','33','41','42','43', '51','52','53'] # \n",
    "start_block_event_times_ssvep = []\n",
    "end_block_event_times_ssvep = []\n",
    "for i in np.arange(len(start_block_event_codes_ssvep)):\n",
    "    event = start_block_event_codes_ssvep[i]\n",
    "    this_time = time_mat[code_mat.index(event)]    \n",
    "    start_block_event_times_ssvep.append(this_time)\n",
    "    end_block_event_times_ssvep.append(this_time + 90) \n",
    "\n",
    "end_block_event_codes_ssvep = ['911','912', '913', '921', '922', '923', '931','932','933','941','942','943', '951','952','953'] #,\n",
    "\n",
    "# create list of start codes and times for resting state blocks\n",
    "start_block_event_codes_rest = ['58','61','62','63','64','65','81','82','83','84','85'] \n",
    "start_block_event_times_rest = []\n",
    "for i in np.arange(len(start_block_event_codes_rest)):    \n",
    "    event = start_block_event_codes_rest[i]\n",
    "    this_time = time_mat[code_mat.index(event)]\n",
    "    start_block_event_times_rest.append(this_time)\n",
    "    \n",
    "# creae list of end codes and times for resting state blocks [these block end codes were logged in the original recording]\n",
    "end_block_event_codes_rest = ['59','71','72','73','74','75','91','92','93','94','95'] \n",
    "end_block_event_times_rest = []\n",
    "for i in np.arange(len(end_block_event_codes_rest)):\n",
    "    event = end_block_event_codes_rest[i]\n",
    "    this_time = time_mat[code_mat.index(event)]\n",
    "    end_block_event_times_rest.append(this_time)\n",
    "\n",
    "# merge lists of codes and times \n",
    "start_block_codes = start_block_event_codes_ssvep + start_block_event_codes_rest\n",
    "start_block_times = start_block_event_times_ssvep + start_block_event_times_rest\n",
    "end_block_codes = end_block_event_codes_ssvep + end_block_event_codes_rest\n",
    "end_block_times = end_block_event_times_ssvep + end_block_event_times_rest\n",
    "\n",
    "print(sorted(start_block_times))\n",
    "\n",
    "## EVENTS CUSTOM CODE ENDS HERE ##\n",
    "\n",
    "\n",
    "# plot green lines for start block codes and red lines for end block codes\n",
    "plt.vlines(x=start_block_times,ymin=-5,ymax=5,linestyles=':',colors = 'g',linewidth=4)\n",
    "plt.vlines(x=end_block_times,ymin=-5,ymax=5,linestyles=':',colors = 'r',linewidth=4)\n",
    "\n",
    "# Set the axis and slider position in the plot\n",
    "bottom_pos = plt.axes([0.2, 0.1, 0.65, 0.03],facecolor = 'white')\n",
    "scroll_slider = Slider(bottom_pos,'time', -1,cont_dict['t'][-1])\n",
    "\n",
    "# Make a vertically oriented slider to control the amplitude\n",
    "right_pos = plt.axes([.95, 0.25, 0.0225, 0.63])\n",
    "y_zoom = Slider(right_pos,label=\"Y zoom\",valmin=0,valmax=1,valinit=.5,orientation=\"vertical\")\n",
    "left_pos = plt.axes([.05, 0.25, 0.0225, 0.63])\n",
    "x_zoom = Slider(left_pos,label=\"X zoom\",valmin=0,valmax=1,valinit=.5,orientation=\"vertical\")\n",
    "\n",
    "ax.set_ylim(-np.median(peak_vals)*4*.5,np.median(peak_vals)*4*.5)\n",
    "\n",
    "ax.set_xlim(-1,9)\n",
    "\n",
    "orig_n = len(peak_times)\n",
    "\n",
    "ax.set_title('Cell 3: remove / add acceleration peaks. Orig: '+str(orig_n)+', Updated: '+str(orig_n))\n",
    "\n",
    "def update(val):\n",
    "    pos = scroll_slider.val\n",
    "    yzoom = y_zoom.val\n",
    "    xzoom = x_zoom.val\n",
    "    ax.set_xlim(pos, pos+20*xzoom)\n",
    "    fig.canvas.draw_idle\n",
    "    ecc=np.median(peak_vals)*4*yzoom\n",
    "    ax.set_ylim(-ecc, ecc)\n",
    "    fig.canvas.draw_idle\n",
    "    \n",
    "# update function called using on_changed() function\n",
    "scroll_slider.on_changed(update)\n",
    "y_zoom.on_changed(update)\n",
    "x_zoom.on_changed(update)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "def onclick(event):\n",
    "    global peak_times,peak_vals,fig,peak_plot,orig_n,ax\n",
    "    ix, iy, ib, ik, iax = event.xdata, event.ydata, event.button, event.key, event.inaxes\n",
    "    if (ix!=None) & (iax==ax):\n",
    "        if (np.min(np.abs(ix-peak_times))<100) & (event.button!=1) & (ik==None):\n",
    "            peak_times,peak_vals,peak_plot=remove_point(ix,peak_times,peak_vals,peak_plot)\n",
    "            ax.set_title('Cell 3: remove / add acceleration peaks. Orig: '+str(orig_n)+', Updated: '+str(len(peak_vals)))\n",
    "        elif (event.button==1) & (ik==None) & (ix>0) & (ix>0) & (iy<np.max(peak_vals)*1.2): #update dist from pos\n",
    "            peak_times,peak_vals,peak_plot=add_point(ix,iy,peak_times,peak_vals,peak_plot)\n",
    "            ax.set_title('Cell 3: remove / add acceleration peaks. Orig: '+str(orig_n)+', Updated: '+str(len(peak_vals)))\n",
    "        elif (event.button==1)&(ik=='m'):\n",
    "            peak_times,peak_vals,peak_plot=meap_dat(ix,iy,peak_times,peak_vals,peak_plot)\n",
    "            ax.set_title('Cell 3: remove / add acceleration peaks. Orig: '+str(orig_n)+', Updated: '+str(len(peak_vals)))\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        \n",
    "        if not plt.fignum_exists(1):\n",
    "            canvas.mpl_disconnect(cid)\n",
    "            canvas.mpl_disconnect(cidk)\n",
    "    return peak_times,peak_vals\n",
    "\n",
    "def onarrow(e):\n",
    "    global scroll_slider\n",
    "    if e.key == \"right\":\n",
    "        pos = ax.get_xlim()\n",
    "        scroll_slider.set_val(pos[0]+.500)\n",
    "    elif e.key == \"left\":\n",
    "        pos = ax.get_xlim()\n",
    "        scroll_slider.set_val(pos[0]-.500)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "cidk = fig.canvas.mpl_connect('key_press_event', onarrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3919a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CELL 4: INTERACTIVE PLOT - FINAL CHECK - PEAKS IN CONTRACTILITY TIME SERIES###\n",
    "# run this cell to open the interactive plot to visualise and amend peak amplitudes in the contractility time series\n",
    "# you can no longer remove and add peaks to the dataset, only adjust their amplitudes\n",
    "# left click - adjust amplitude\n",
    "# hold m and left click - use moving average to estimate peak amplitude\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "import numpy as np\n",
    "from sys_SCOT_Event_Related import *\n",
    "\n",
    "##Store acceleration peaks and times\n",
    "cont_dict['acc_peaks']=peak_vals\n",
    "cont_dict['acc_peak_times']=peak_times\n",
    "\n",
    "%matplotlib tk\n",
    "plt.close('all')\n",
    "fig,ax = plt.subplots()\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "#estimating heartrate before estimating contractility\n",
    "cont_dict['RR']=np.hstack([np.nan,np.diff(peak_times)])\n",
    "\n",
    "#estimate contractility from acceleration and adjust times etc.\n",
    "cont_s = np.diff(cont_dict['s'])\n",
    "cont_t = cont_dict['t'][1:]\n",
    "init_cont_inds = peak_inds+1\n",
    "cont_inds = shift_peaks_no_plot(250,peak_times,cont_t,cont_s,init_cont_inds)\n",
    "peak_times = cont_t[cont_inds]\n",
    "peak_vals = cont_s[cont_inds]\n",
    "\n",
    "w = ax.plot(cont_t,cont_s)\n",
    "peak_plot, = ax.plot(peak_times,peak_vals ,'vm')\n",
    "\n",
    "# Set the axis and slider position in the plot\n",
    "bottom_pos = plt.axes([0.2, 0.1, 0.65, 0.03],facecolor = 'white')\n",
    "scroll_slider = Slider(bottom_pos,'time', -1,cont_t[-1])\n",
    "\n",
    "# Make a vertically oriented slider to control the amplitude\n",
    "right_pos = plt.axes([.95, 0.25, 0.0225, 0.63])\n",
    "y_zoom = Slider(right_pos,label=\"Y zoom\",valmin=0,valmax=.1,valinit=.05,orientation=\"vertical\")\n",
    "left_pos = plt.axes([.05, 0.25, 0.0225, 0.63])\n",
    "x_zoom = Slider(left_pos,label=\"X zoom\",valmin=0,valmax=1,valinit=.5,orientation=\"vertical\")\n",
    "\n",
    "ax.set_ylim(-(np.median(peak_vals)+.05),np.median(peak_vals)+.05)\n",
    "\n",
    "ax.set_xlim(-1,9)\n",
    "\n",
    "ax.set_title('Cell 4: adjust contractility amplitudes only')\n",
    "\n",
    "def update(val):\n",
    "    pos = scroll_slider.val\n",
    "    yzoom = y_zoom.val\n",
    "    xzoom = x_zoom.val\n",
    "    ax.set_xlim(pos, pos+20*xzoom)\n",
    "    fig.canvas.draw_idle\n",
    "    ecc=np.median(peak_vals)+yzoom\n",
    "    ax.set_ylim(-ecc, ecc)\n",
    "    fig.canvas.draw_idle\n",
    "    \n",
    "# update function called using on_changed() function\n",
    "scroll_slider.on_changed(update)\n",
    "y_zoom.on_changed(update)\n",
    "x_zoom.on_changed(update)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "def onclick(event):\n",
    "    global peak_times,peak_vals,fig,peak_plot\n",
    "    ix, iy, ib, ik, iax = event.xdata, event.ydata, event.button, event.key, event.inaxes\n",
    "    if (ix!=None) & (iax==ax):\n",
    "        if (event.button==1) & (ik==None) & (ix>0) & (ix>0) & (iy<np.max(peak_vals)*1.2): \n",
    "            peak_times,peak_vals,peak_plot=adjust_peak_amp(ix,iy,peak_times,peak_vals,peak_plot)\n",
    "        elif (event.button==1)&(ik=='m'):\n",
    "            peak_times,peak_vals,peak_plot=meap_dat_cell4(ix,iy,peak_times,peak_vals,peak_plot)\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        \n",
    "        if not plt.fignum_exists(1):\n",
    "            canvas.mpl_disconnect(cid)\n",
    "            canvas.mpl_disconnect(cidk)\n",
    "            \n",
    "    return peak_times,peak_vals\n",
    "\n",
    "def onarrow(e):\n",
    "    global scroll_slider\n",
    "    if e.key == \"right\":\n",
    "        pos = ax.get_xlim()\n",
    "        scroll_slider.set_val(pos[0]+.500)\n",
    "    elif e.key == \"left\":\n",
    "        pos = ax.get_xlim()\n",
    "        scroll_slider.set_val(pos[0]-.500)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "cidk = fig.canvas.mpl_connect('key_press_event', onarrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d43d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CELL 5: OUTPUT DATA TO CSV ###\n",
    "# This cell will model respiration and heart-rate out of the beatwise contractility estimates and output the following files:\n",
    "# (1) Contractility estimates (XXX.csv)\n",
    "# (2) Blood Pressure (XXX_bp.csv)\n",
    "# (3) Respiration (XXX_resp.csv)\n",
    "# (4) Event Codes (XXX_events.csv)\n",
    "\n",
    "# These files can then be used for event-related analyses.\n",
    "\n",
    "import pandas as pd\n",
    "from sys_SCOT_Event_Related import regress_out,outsave_box\n",
    "plt.close('all')\n",
    "\n",
    "## output contractility\n",
    "cont_dict['cont_peak_times']=peak_times\n",
    "cont_dict['raw_contractility_peaks']=peak_vals\n",
    "cont_dict=regress_out(cont_dict)\n",
    "\n",
    "out_f = outsave_box(file_path[:-4]+'.csv')\n",
    "\n",
    "out_dict={}\n",
    "out_dict['time']=cont_dict['cont_peak_times']\n",
    "out_dict['resid_contractility']=cont_dict['resid_contractility'] # renamed contractility >resid_contractility\n",
    "out_dict['raw_contractility']=cont_dict['raw_contractility_peaks'] # added this output in case need to re-run pipeline later\n",
    "pd.DataFrame(out_dict).to_csv(out_f)\n",
    "\n",
    "# ouput event codes and corresponding timestamps\n",
    "if 'events_s' in cont_dict: # dict will only contain \"events_s\" key if event channel present and selected in prepro\n",
    "    out_f_event = out_f[:-4] + '_events.csv' #outsave_box(file_path[:-4]+'_events.csv')\n",
    "    \n",
    "    events = cont_dict['events_s']\n",
    "    times = cont_dict['events_t']\n",
    "    \n",
    "    code_mat = []\n",
    "    time_mat = []\n",
    "    \n",
    "    # cut out redundant events from oversampling\n",
    "    for i in np.arange(np.shape(events)[0]): \n",
    "        if events[i] != 0 and events[i-1] != events[i]:       \n",
    "            code_mat.append(int(events[i]))\n",
    "            time_mat.append(round(times[i],3))\n",
    "    \n",
    "    # create df with event codes and timestamps and write to csv\n",
    "    pd.DataFrame({'time':time_mat,'code':code_mat}).to_csv(out_f_event)\n",
    "    \n",
    "# output continuous blood pressure\n",
    "if 'bp_s' in cont_dict: # if there's bp data present\n",
    "    out_f_bp = out_f[:-4] + '_bp.csv'\n",
    "    \n",
    "    # grab bp times and values and downsample from 1000 Hz to 10 Hz\n",
    "    #times=np.round(cont_dict['bp_t'][0:-1:100],1)\n",
    "    #bp = np.round(cont_dict['bp_s'][0:-1:100],3)\n",
    "    times=np.round(cont_dict['bp_t'][0:-1:10],2)\n",
    "    bp = np.round(cont_dict['bp_s'][0:-1:10],3)\n",
    "\n",
    "    pd.DataFrame({'time':times,'bp':bp}).to_csv(out_f_bp)\n",
    "\n",
    "# output respiration\n",
    "if 'raw_resp_s' in cont_dict: # if there's raw respiration data present\n",
    "    out_f_resp = out_f[:-4] + '_resp.csv'\n",
    "    \n",
    "    # grab resp times and values and downsample from 1000 Hz to 10 Hz\n",
    "    times=np.round(cont_dict['raw_resp_t'][0:-1:100],1)\n",
    "    resp = np.round(cont_dict['raw_resp_s'][0:-1:100],3)\n",
    "    #resp = cont_dict['raw_resp_s']\n",
    "\n",
    "    pd.DataFrame({'time':times,'resp':resp}).to_csv(out_f_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e6ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab24a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa494e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
